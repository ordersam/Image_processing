{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪圖設定字體顏色(否則黑色會看不到)\n",
    "import matplotlib as mpl\n",
    "COLOR1 = 'red'\n",
    "COLOR2 = 'blue'\n",
    "mpl.rcParams['text.color'] = COLOR1\n",
    "mpl.rcParams['axes.labelcolor'] = COLOR2\n",
    "mpl.rcParams['xtick.color'] = COLOR2\n",
    "mpl.rcParams['ytick.color'] = COLOR2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.OpenCV臉部比對函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBPHFaceRecognizer label = 0\n",
      "LBPHFaceRecognizer confidence = 67.6856704732354\n",
      "EigenFaceRecognizer label = 0\n",
      "EigenFaceRecognizer confidence = 839.5760877931219\n",
      "FisherFaceRecognizer label = 0\n",
      "FisherFaceRecognizer confidence = 597.4287226710123\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# 灰階讀取影像\n",
    "images = []\n",
    "images.append(cv2.imread(\"data/a1.png\", cv2.IMREAD_GRAYSCALE))\n",
    "images.append(cv2.imread(\"data/a2.png\", cv2.IMREAD_GRAYSCALE))\n",
    "images.append(cv2.imread(\"data/b1.png\", cv2.IMREAD_GRAYSCALE))\n",
    "images.append(cv2.imread(\"data/b2.png\", cv2.IMREAD_GRAYSCALE))\n",
    "# 標示：同一個人標示同一編碼\n",
    "labels = [0, 0, 1, 1]\n",
    "\n",
    "# 1.LBP演算法(LBPHFaceRecognizer)\n",
    "# 訓練\n",
    "face_recognizer1 = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer1.train(images, np.array(labels)) \n",
    "# 預測\n",
    "predict_image = cv2.imread(\"0.data/Face_Detection with_Deep Learning_in_Keras/a3.png\", cv2.IMREAD_GRAYSCALE)\n",
    "label1, confidence1 = face_recognizer1.predict(predict_image) \n",
    "print(\"LBPHFaceRecognizer label =\", label1)\n",
    "print(\"LBPHFaceRecognizer confidence =\", confidence1)\n",
    "\n",
    "# 2.EigenFaceRecognizer\n",
    "face_recognizer2 = cv2.face.EigenFaceRecognizer_create()\n",
    "face_recognizer2.train(images, np.array(labels)) \n",
    "# 預測\n",
    "label2, confidence2 = face_recognizer2.predict(predict_image) \n",
    "print(\"EigenFaceRecognizer label =\", label2)\n",
    "print(\"EigenFaceRecognizer confidence =\", confidence2)\n",
    "\n",
    "# 3.FisherFaceRecognizer\n",
    "face_recognizer3 = cv2.face.FisherFaceRecognizer_create()\n",
    "face_recognizer3.train(images, np.array(labels)) \n",
    "# 預測\n",
    "label3, confidence3 = face_recognizer3.predict(predict_image) \n",
    "print(\"FisherFaceRecognizer label =\", label3)\n",
    "print(\"FisherFaceRecognizer confidence =\", confidence3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 產生128D numpy特徵向量\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "# 圖片 轉RGB\n",
    "image = cv2.imread(\"data/jared_1.jpg\")\n",
    "rgb = image[:, :, ::-1]\n",
    "\n",
    "# (1)正面人臉偵測器\n",
    "    # rects = detector(圖像, 0) 回傳值 rectangles[第一張臉[(左上x, 左上y) (右下x, 右下y)], ...]\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# (2)訓練好的 人臉特徵檢測器(5點)：檔案太大，請自行搜尋下載\n",
    "    # shape = predictor(圖像, rects[i]) 轉numpy 就是 特徵點座標 list\n",
    "pose_predictor_5_point = dlib.shape_predictor(\"data/shape_predictor_5_face_landmarks.dat\")\n",
    "# (3)生成面部識別器\n",
    "    # 特徵點 轉換為 128D面部描述，同一人轉換後特徵位置相近，可用來 臉部比對 是否同一人\n",
    "    # face_encoder.compute_face_descriptor(圖像, 人臉特徵檢測器shape, num_jitters=如果大於1表示輕度隨機晃動次數)\n",
    "    # 模型檔下載\n",
    "        # https://github.com/davisking/dlib-models/blob/master/dlib_face_recognition_resnet_model_v1.dat.bz2\n",
    "face_encoder = dlib.face_recognition_model_v1(\"data/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "\n",
    "def face_encodings(face_image, number_of_times_to_upsample=1, num_jitters=1):\n",
    "    # (1)人臉位置\n",
    "    face_locations = detector(face_image, number_of_times_to_upsample)\n",
    "    # (2)人臉特徵(沒有轉numpy) list\n",
    "    raw_landmarks = [pose_predictor_5_point(face_image, face_location) for face_location in face_locations]\n",
    "    # (3)128D面部描述 list\n",
    "    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for\n",
    "            raw_landmark_set in raw_landmarks]\n",
    "# 所有人臉 128D面部描述 list\n",
    "    # [第一張臉 numpy shape=(128,), 第二張, ...]\n",
    "encodings = face_encodings(rgb)\n",
    "for encoding in encodings:\n",
    "    print(len(encoding))\n",
    "    print(type(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "距離list = [0.39983264838593896, 0.4104153683230741, 0.3913191431497527, 0.9053700273411349]\n",
      "排序後距離list = (0.3913191431497527, 0.39983264838593896, 0.4104153683230741, 0.9053700273411349)\n",
      "相似圖像排序list = ('jared_3.jpg', 'jared_1.jpg', 'jared_2.jpg', 'obama.jpg')\n"
     ]
    }
   ],
   "source": [
    "# 128D numpy特徵向量 進行人臉比對\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "# 圖片\n",
    "known_image_1 = cv2.imread(\"data/jared_1.jpg\")\n",
    "known_image_2 = cv2.imread(\"data/jared_2.jpg\")\n",
    "known_image_3 = cv2.imread(\"data/jared_3.jpg\")\n",
    "known_image_4 = cv2.imread(\"data/obama.jpg\")\n",
    "unknown_image = cv2.imread(\"data/jared_4.jpg\")\n",
    "# 轉RGB\n",
    "known_image_1 = known_image_1[:, :, ::-1]\n",
    "known_image_2 = known_image_2[:, :, ::-1]\n",
    "known_image_3 = known_image_3[:, :, ::-1]\n",
    "known_image_4 = known_image_4[:, :, ::-1]\n",
    "unknown_image = unknown_image[:, :, ::-1]\n",
    "# 圖片名稱\n",
    "names = [\"jared_1.jpg\", \"jared_2.jpg\", \"jared_3.jpg\", \"obama.jpg\"]\n",
    "\n",
    "# (1)正面人臉偵測器\n",
    "    # rects = detector(圖像, 0) 回傳值 rectangles[第一張臉[(左上x, 左上y) (右下x, 右下y)], ...]\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# (2)訓練好的 人臉特徵檢測器(5點)\n",
    "    # shape = predictor(圖像, rects[i]) 轉numpy 就是 特徵點座標 list\n",
    "pose_predictor_5_point = dlib.shape_predictor(\"data/shape_predictor_5_face_landmarks.dat\")\n",
    "# (3)生成面部識別器\n",
    "    # 特徵點 轉換為 128D面部描述，同一人轉換後特徵位置相近，可用來 臉部比對 是否同一人\n",
    "    # face_encoder.compute_face_descriptor(圖像, 人臉特徵檢測器shape, num_jitters=如果大於1表示輕度隨機晃動次數)\n",
    "    # 模型檔下載\n",
    "        # https://github.com/davisking/dlib-models/blob/master/dlib_face_recognition_resnet_model_v1.dat.bz2\n",
    "face_encoder = dlib.face_recognition_model_v1(\"data/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "\n",
    "def face_encodings(face_image, number_of_times_to_upsample=1, num_jitters=1):\n",
    "    # (1)人臉位置\n",
    "    face_locations = detector(face_image, number_of_times_to_upsample)\n",
    "    # (2)人臉特徵(沒有轉numpy) list\n",
    "    raw_landmarks = [pose_predictor_5_point(face_image, face_location) for face_location in face_locations]\n",
    "    # (3)128D面部描述 list\n",
    "    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for\n",
    "            raw_landmark_set in raw_landmarks]\n",
    "# 128D面部描述：只有一張臉 shape=(128,)\n",
    "known_image_1_encoding = face_encodings(known_image_1)[0]\n",
    "known_image_2_encoding = face_encodings(known_image_2)[0]\n",
    "known_image_3_encoding = face_encodings(known_image_3)[0]\n",
    "known_image_4_encoding = face_encodings(known_image_4)[0]\n",
    "known_encodings = [known_image_1_encoding, known_image_2_encoding, known_image_3_encoding, known_image_4_encoding]\n",
    "unknown_encoding = face_encodings(unknown_image)[0]\n",
    "\n",
    "# 比較距離後排序(小到大)：(距離, 名稱)\n",
    "    # sorted(iterable, reverse=False改True由大到小排序)\n",
    "def compare_faces_ordered(encodings, face_names, encoding_to_check):\n",
    "    distances = list(np.linalg.norm(encodings - encoding_to_check, axis=1))\n",
    "    return zip(*sorted(zip(distances, face_names)))\n",
    "\n",
    "# 比較距離：(所有臉的128D面部描述 list, 要比較的那張臉128D面部描述)\n",
    "def compare_faces(encodings, encoding_to_check):\n",
    "    # np.linalg.norm 回傳範數(距離)\n",
    "    return list(np.linalg.norm(encodings - encoding_to_check, axis=1))\n",
    "\n",
    "computed_distances = compare_faces(known_encodings, unknown_encoding)\n",
    "computed_distances_ordered, ordered_names = compare_faces_ordered(known_encodings, names, unknown_encoding)\n",
    "\n",
    "# Print obtained results\n",
    "print('距離list =', computed_distances)\n",
    "print('排序後距離list =', computed_distances_ordered)\n",
    "print('相似圖像排序list =', ordered_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.face_recognition：face_encodings編碼 人臉比對"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the unknown face a picture of ciaburro? False\n",
      "Is the unknown face a picture of Tiziana? True\n",
      "Is the unknown face a new person that we've never seen before? False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import face_recognition\n",
    "# 載入圖片：RBG\n",
    "Image1 = face_recognition.load_image_file(\"data/ciaburro.jpg\")\n",
    "Image2 = face_recognition.load_image_file(\"data/tiziana.jpg\")\n",
    "UnknownImage = face_recognition.load_image_file(\"data/tiziana2.jpg\")\n",
    "# face_encodings 分析影像 並計算 128個維度臉部編碼 shape=(128,)\n",
    "try:\n",
    "    Image1Encoding = face_recognition.face_encodings(Image1)[0]\n",
    "    Image2Encoding = face_recognition.face_encodings(Image2)[0]\n",
    "    UnknownImageEncoding = face_recognition.face_encodings(UnknownImage)[0]\n",
    "except IndexError:\n",
    "    print(\"Any face was located. Check the image files..\")\n",
    "    quit()\n",
    "# 已知臉部list 轉編碼，比較第三張臉\n",
    "    # results 回傳 [是否 1st的臉, ...]\n",
    "known_faces = [Image1Encoding, Image2Encoding]\n",
    "results = face_recognition.compare_faces(known_faces, UnknownImageEncoding)\n",
    "\n",
    "print(\"Is the unknown face a picture of ciaburro? {}\".format(results[0]))\n",
    "print(\"Is the unknown face a picture of Tiziana? {}\".format(results[1]))\n",
    "print(\"Is the unknown face a new person that we've never seen before? {}\".format(not True in results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
