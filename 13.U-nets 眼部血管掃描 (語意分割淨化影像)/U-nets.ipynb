{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 512)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 9438208     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 1024) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 1024) 0           dropout[0][0]                    \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 256 0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 147584      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 2)  1154        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 1)  3           conv2d_22[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,031,685\n",
      "Trainable params: 31,031,685\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout, concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# 模型：\n",
    "def unet(pretrained_weights=None, input_size=(256, 256, 1)):\n",
    "    # Encoder\n",
    "    inputs = tf.keras.Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)  # 介接\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)  # 介接\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)  # 介接\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)                                                                       # 介接\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    # 共用\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    # Decoder\n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)  # 介接到Encoder drop4\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)  # 介接到Encoder conv3\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)  # 介接到Encoder conv2\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)  # 介接到Encoder conv1\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    \n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4), \n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # 如果有權重就載入\n",
    "    if (pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "    return model\n",
    "model = unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料前處理：mask(多分類one hot encoding，二分類二值化)、標準化\n",
    "def adjustData(img, mask, flag_multi_class, num_class):\n",
    "    # 輸出是否多分類(分割圖是否超過二個顏色)\n",
    "        # mask每個像素值，進行one hot分類\n",
    "        # flag_multi_class=True, num_class=分類數目\n",
    "        # 多分類要配合修改模型\n",
    "            # conv10 = Conv2D(分類數目, 1, activation='sigmoid')(conv9)\n",
    "            # model.compile 的 loss 改成 'categorical_crossentropy'\n",
    "    if (flag_multi_class):\n",
    "        img = img / 255\n",
    "        # 灰階去掉最裡面的維度，shape=(batch, 高, 寬) 或 (高, 寬)\n",
    "        mask = mask[:, :, :, 0] if (len(mask.shape)==4) else mask[:, :, 0]\n",
    "        # 空矩陣 最裡面是進行one hot的維度\n",
    "            # mask.shape + (num_class,)=(高, 寬, num_class)\n",
    "        new_mask = np.zeros(mask.shape + (num_class,))\n",
    "        # 原來的像素值進行one hot分類\n",
    "        for i in range(num_class):\n",
    "            new_mask[mask == i, i] = 1\n",
    "        # reshape=(batch, 高*寬, num_class) 或 (高*寬, num_class)\n",
    "        new_mask = np.reshape(\n",
    "            new_mask, (new_mask.shape[0], new_mask.shape[1]*new_mask.shape[2], new_mask.shape[3])) \\\n",
    "            if flag_multi_class else np.reshape(new_mask, \n",
    "                                                (new_mask.shape[0]*new_mask.shape[1], \n",
    "                                                 new_mask.shape[2]))\n",
    "        mask = new_mask\n",
    "    # 如果原圖沒有標準化\n",
    "    elif (np.max(img) > 1):\n",
    "        # 標準化\n",
    "        img = img / 255\n",
    "        mask = mask /255\n",
    "        # mask二值化\n",
    "        mask[mask > 0.5] = 1\n",
    "        mask[mask <= 0.5] = 0\n",
    "    return (img, mask)\n",
    "\n",
    "# 訓練資料生成器 生成資料=(img, mask)\n",
    "def trainGenerator(batch_size, train_path, image_folder, mask_folder, aug_dict, target_size=(256, 256), \n",
    "                   image_color_mode=\"grayscale\", mask_color_mode=\"grayscale\", \n",
    "                   save_to_dir=None, image_save_prefix=\"image\", mask_save_prefix=\"mask\", seed=1, \n",
    "                   flag_multi_class=False, num_class=2):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path, target_size=target_size, color_mode=image_color_mode, \n",
    "        classes=[image_folder], class_mode=None, batch_size=batch_size, \n",
    "        save_to_dir=save_to_dir, save_prefix=image_save_prefix, seed=seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path, target_size=target_size, color_mode=mask_color_mode, \n",
    "        classes=[mask_folder], class_mode=None, batch_size=batch_size, \n",
    "        save_to_dir=save_to_dir, save_prefix=mask_save_prefix, seed=seed)\n",
    "    # 將生成器組合成 圖像 + 處理過後分割圖的生成器(mask)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    # 前處理：mask(多分類one hot encoding，二分類二值化)、標準化\n",
    "    for (img, mask) in train_generator:\n",
    "        img, mask = adjustData(img, mask, flag_multi_class, num_class)\n",
    "        yield (img, mask)\n",
    "\n",
    "# 測試資料生成器：逐一讀取 0.png到29.png 回傳\n",
    "def testGenerator(test_path, num_image=30, target_size=(256, 256), \n",
    "                  flag_multi_class=False, as_gray=True):\n",
    "    for i in range(num_image):\n",
    "        # 灰階讀取 0.png到29.png\n",
    "        img = io.imread(os.path.join(test_path, \"%d.png\"%i), as_gray=as_gray)\n",
    "        # 標準化\n",
    "        img = img / 255\n",
    "        # (256, 256)\n",
    "        img = trans.resize(img, target_size)\n",
    "        # 加一維：(256, 256, 1)\n",
    "        img = np.reshape(img, img.shape+(1,)) if (not flag_multi_class) else img\n",
    "        # 加上batch：(1, 256, 256, 1)\n",
    "        img = np.reshape(img, (1,)+img.shape)\n",
    "        yield img\n",
    "\n",
    "# 讀取指定路徑資料夾\n",
    "def geneTrainNpy(image_path, mask_path, flag_multi_class=False, num_class=2, image_prefix=\"image\", \n",
    "                 mask_prefix=\"mask\", image_as_gray=True, mask_as_gray=True):\n",
    "    image_name_arr = glob.glob(os.path.join(image_path, \"%s*.png\" % image_prefix))\n",
    "    image_arr = []\n",
    "    mask_arr = []\n",
    "    for index, item in enumerate(image_name_arr):\n",
    "        img = io.imread(item, as_gray=image_as_gray)\n",
    "        img = np.reshape(img, img.shape+(1,)) if image_as_gray else img\n",
    "        mask = io.imread(item.replace(image_path, mask_path).replace(image_prefix, mask_prefix), \n",
    "                         as_gray=mask_as_gray)\n",
    "        mask = np.reshape(mask, mask.shape+(1,)) if mask_as_gray else mask\n",
    "        img,mask = adjustData(img, mask,flag_multi_class, num_class)\n",
    "        image_arr.append(img)\n",
    "        mask_arr.append(mask)\n",
    "    image_arr = np.array(image_arr)\n",
    "    mask_arr = np.array(mask_arr)\n",
    "    return image_arr, mask_arr\n",
    "\n",
    "# 標示顏色\n",
    "Sky = [128, 128, 128]\n",
    "Building = [128, 0, 0]\n",
    "Pole = [192, 192, 128]\n",
    "Road = [128, 64, 128]\n",
    "Pavement = [60, 40, 222]\n",
    "Tree = [128, 128, 0]\n",
    "SignSymbol = [192, 128, 128]\n",
    "Fence = [64, 64,128]\n",
    "Car = [64, 0, 128]\n",
    "Pedestrian = [64, 64, 0]\n",
    "Bicyclist = [0, 128, 192]\n",
    "Unlabelled = [0, 0, 0]\n",
    "COLOR_DICT = np.array([Sky, Building, Pole, Road, Pavement, Tree, SignSymbol, \n",
    "                       Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n",
    "\n",
    "# 多分類處理：參數(分類數目, 可供標示的顏色dict, 預測出的mask圖)\n",
    "def labelVisualize(num_class, color_dict, img):\n",
    "    img = img[:, :, 0] if len(img.shape) == 3 else img  # shape=(寬, 高)\n",
    "    img_out = np.zeros(img.shape+(num_class,))          # shape=(寬, 高, 分類數目)\n",
    "    for i in range(num_class):\n",
    "        img_out[img==i, :] = color_dict[i]\n",
    "    return img_out / 255\n",
    "\n",
    "# 預測圖片存檔\n",
    "def saveResult(save_path, npyfile, flag_multi_class=False, num_class=2):\n",
    "    for i, item in enumerate(npyfile):\n",
    "        # 多分類處理\n",
    "        img = (labelVisualize(num_class, COLOR_DICT, item) if flag_multi_class else item[:, :, 0])\n",
    "        io.imsave(os.path.join(save_path, \"%d_predict.png\" % i), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.3408 - accuracy: 0.8517\n",
      "Epoch 00001: loss improved from inf to 0.34077, saving model to 0.data/U-nets/keras/unet-master/unet_membrane.hdf5\n",
      "300/300 [==============================] - 183s 609ms/step - loss: 0.3408 - accuracy: 0.8518\n",
      "30/30 [==============================] - 5s 166ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# 生成資料\n",
    "data_gen_args = dict(\n",
    "    rotation_range=0.2, width_shift_range=0.05, height_shift_range=0.05, \n",
    "    shear_range=0.05, zoom_range=0.05, horizontal_flip=True, fill_mode='nearest')\n",
    "    # 參數 (batch_size, 資料路徑, 路徑下的影像資料夾, 路徑下的mask影像資料夾, \n",
    "    #      ImageDataGenerator參數, 存檔路徑)\n",
    "myGene = trainGenerator(\n",
    "    2, '0.data/U-nets/keras/unet-master/data/membrane/train', 'image', 'label', \n",
    "    data_gen_args, save_to_dir=None)\n",
    "# 模型\n",
    "model = unet()\n",
    "# 訓練\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    '0.data/U-nets/keras/unet-master/unet_membrane.hdf5', \n",
    "    monitor='loss', save_best_only=True, verbose=1)\n",
    "model.fit_generator(myGene, steps_per_epoch=300, epochs=1, callbacks=[model_checkpoint])\n",
    "\n",
    "# 預測\n",
    "    # 測試資料生成器：逐一讀取 0.png到29.png 回傳\n",
    "testGene = testGenerator(\"0.data/U-nets/keras/unet-master/data/membrane/test\")\n",
    "    # 預測出淨化後的分割圖\n",
    "        # predict_generator參數\n",
    "            # (生成器, steps=生成器應該返回的總樣本數, \n",
    "            #  max_queue_size=10生成器隊列的最大容量, workers=1同時處理(多線程), \n",
    "            #  use_multiprocessing=False是否使用多線程, verbose=0顯示設定)\n",
    "results = model.predict_generator(testGene, 30, verbose=1)\n",
    "    # 預測圖片存檔\n",
    "saveResult(\"0.data/U-nets/keras/unet-master/data/membrane/result\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
